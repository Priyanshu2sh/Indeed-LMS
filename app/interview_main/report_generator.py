import datetime
import json
import re
from .config import generator

def generate_report(level, interview_type, evaluation_log):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # Candidate name detection from first answer
    candidate_name = "N/A"
    for entry in evaluation_log:
        answer = entry.get("answer","")
        # extract first capitalized word sequence
        matches = re.findall(r'\b[A-Z][a-z]+\b', answer)
        if matches:
            candidate_name = matches[0]
            break

    # Determine HR or Technical questions
    is_technical = interview_type.lower() == "technical"
    is_hr = interview_type.lower() == "hr"

    hr_questions = [] if is_technical else [q for q in evaluation_log if "behavior" in q.get("question","").lower() or "team" in q.get("question","").lower()]
    tech_questions = [] if is_hr else [q for q in evaluation_log if q not in hr_questions]

    # Correct common technical terms spelling in answers
    def correct_spelling(text):
        corrections = {
            r"\bhtml\b": "HTML",
            r"\bcss\b": "CSS",
            r"\bjavascript\b": "JavaScript",
            r"\breact\b": "React",
            r"\bnode\.js\b": "Node.js",
            r"\bpython\b": "Python",
            r"\bmern\b": "MERN"
        }
        for pattern, repl in corrections.items():
            text = re.sub(pattern, repl, text, flags=re.IGNORECASE)
        return text

    def section_summary(entries, section_name):
        if not entries:
            return f"{section_name}:\nNo questions answered.\n"

        summary_lines = [f"{section_name}:"]
        strengths = set()
        weaknesses = set()
        total_score = 0

        for i, entry in enumerate(entries, 1):
            q = correct_spelling(entry.get("question", "N/A"))
            a = correct_spelling(entry.get("answer", "N/A"))
            relevance = entry.get("relevance", 0)
            technical = entry.get("technical_correctness", 0)
            clarity = entry.get("clarity", 0)
            avg_score = round((relevance + technical + clarity)/3, 2)
            total_score += avg_score

            comment = entry.get("comment","") if i > 1 else ""

            summary_lines.append(f"Q{i}: {q}\nA{i}: {a}\n{'Comment: '+comment if comment else ''}\nScore: {avg_score}/5\n")

            # Strength skills
            if technical >= 4:
                strengths.add("Technical Knowledge")
            if relevance >= 4:
                strengths.add("Answer Relevance")
            if clarity >= 4:
                strengths.add("Communication Clarity")

            # Weak skill areas
            if relevance < 3:
                weaknesses.add("Relevance")
            if technical < 3:
                weaknesses.add("Technical Correctness")
            if clarity < 3:
                weaknesses.add("Clarity")

        avg_section_score = round(total_score / len(entries), 2)
        summary_lines.append(f"Section Average Score: {avg_section_score}/5")
        summary_lines.append("Strengths: " + (", ".join(strengths) if strengths else "None"))
        summary_lines.append("Weaknesses: " + (", ".join(weaknesses) if weaknesses else "None"))

        return "\n".join(summary_lines)

    # AI-generated overall summary
    try:
        prompt = f"Summarize the candidate's interview performance from this log:\n{json.dumps(evaluation_log, indent=2)}\nHighlight strengths, weaknesses, and engagement concisely."
        overall_summary = generator(prompt, max_tokens=200)
    except Exception:
        overall_summary = "Could not generate AI summary. Please see detailed evaluation below."

    candidate_details = f"""
ðŸ“„ Final Interview Report (Generated by Chatbot)
1. Candidate Details
Name: {candidate_name}
Interview Mode: {interview_type.capitalize()}
Difficulty Level: {level.capitalize()}
Date & Time: {now}
"""

    interview_summary = f"""
2. Interview Summary
{overall_summary}
Total Questions Answered: {len(evaluation_log)}
"""

    hr_section = section_summary(hr_questions, "3a) HR Questions") if not is_technical else ""
    tech_section = section_summary(tech_questions, "3b) Technical Questions") if not is_hr else ""

    # Overall Performance
    overall_score = round(sum((q.get("relevance",0)+q.get("technical_correctness",0)+q.get("clarity",0))/3 for q in evaluation_log)/len(evaluation_log),2) if evaluation_log else 0
    rating_stars = "â­"*round(overall_score) + "â˜†"*(5-round(overall_score))
    overall_section = f"""
4. Overall Performance
Average Score: {overall_score}/5
Rating: {rating_stars}
"""

    # Recommendations
    weak_fields = set()
    for entry in evaluation_log[1:]:  # skip intro
        if entry.get("relevance",0) < 3:
            weak_fields.add("Relevance")
        if entry.get("technical_correctness",0) < 3:
            weak_fields.add("Technical Correctness")
        if entry.get("clarity",0) < 3:
            weak_fields.add("Clarity")

    rec_lines = []
    if "Technical Correctness" in weak_fields:
        rec_lines.append("Revise HTML, CSS, JavaScript fundamentals; practice MERN stack projects.")
    if "Clarity" in weak_fields:
        rec_lines.append("Practice clear and concise explanations; record and review mock interviews.")
    if "Relevance" in weak_fields:
        rec_lines.append("Focus on answering the question asked; align answers with job requirements.")
    if hr_questions:
        rec_lines.append("Use STAR method for HR questions; review common behavioral questions.")

    recommendations = f"""
5. Recommendations
Suggested actions: {', '.join(rec_lines) if rec_lines else 'Maintain current performance.'}
"""

    # Assemble final report
    final_report = "\n".join([candidate_details, interview_summary, hr_section, tech_section, overall_section, recommendations])

    # print(final_report)

    # return {
    #     "candidate_details": candidate_details,
    #     "interview_summary": interview_summary,
    #     "hr_section": hr_section,
    #     "tech_section": tech_section,
    #     "overall": overall_section,
    #     "recommendations": recommendations,
    #     "evaluation_log": evaluation_log
    # }
    def extract_feedback_sections(text):
        strengths_match = re.search(r"Strengths:\s*(.*?)(?=\n\s*\*\*Weaknesses|\nWeaknesses:|\Z)", text, flags=re.S|re.I)
        weaknesses_match = re.search(r"Weaknesses:\s*(.*?)(?=\n\s*\*\*Engagement|\nEngagement:|\Z)", text, flags=re.S|re.I)
        engagement_match = re.search(r"Engagement:\s*(.*)", text, flags=re.S|re.I)

        def clean(s):
            s = s.strip()
            # Remove leading markdown asterisks and whitespace
            s = re.sub(r"^[\*\s]+", "", s)
            # Remove bullet markers
            s = re.sub(r"[-â€¢]\s*", "", s)
            # Normalize spacing
            s = re.sub(r"\s+", " ", s)
            return s.strip()

        if not strengths_match and not weaknesses_match and not engagement_match:
            return {
                "overall_summary": clean(text)
            }

        return {
            "strengths": clean(strengths_match.group(1)) if strengths_match else "",
            "weaknesses": clean(weaknesses_match.group(1)) if weaknesses_match else "",
            "engagement": clean(engagement_match.group(1)) if engagement_match else ""
        }

    

    return {
        "candidate_details": {
            "name": candidate_name,
            "interview_mode": interview_type.capitalize(),
            "difficulty_level": level.capitalize(),
            "date_time": now
        },
        "interview_summary": {
            "summary_text": extract_feedback_sections(overall_summary.strip()),
            "total_questions": len(evaluation_log)
        },
        "hr_section": [
            {
                "question": correct_spelling(q.get("question", "")),
                "answer": correct_spelling(q.get("answer", "")),
                "comment": q.get("comment", ""),
                "score": round((q.get("relevance",0)+q.get("technical_correctness",0)+q.get("clarity",0))/3,2)
            } for q in hr_questions
        ] if hr_questions else [],
        "tech_section": [
            {
                "question": correct_spelling(q.get("question", "")),
                "answer": correct_spelling(q.get("answer", "")),
                "comment": q.get("comment", ""),
                "score": round((q.get("relevance",0)+q.get("technical_correctness",0)+q.get("clarity",0))/3,2)
            } for q in tech_questions
        ] if tech_questions else [],
        "overall": {
            "average_score": overall_score,
            "rating": rating_stars
        },
        "recommendations": rec_lines,
        "evaluation_log": evaluation_log
    }

