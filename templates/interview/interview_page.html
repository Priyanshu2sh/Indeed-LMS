{% extends "base.html" %} {% block content %}

<style>
  /* Disable scroll everywhere */
  html,
  body {
    height: 100%;
    margin: 0;
    padding: 0;
    overflow: hidden !important;
  }

  /* Disable base file buttons */
  .btn,
  button {
    pointer-events: none;
    opacity: 0.5;
  }

  /* Fullscreen countdown overlay */
  #countdown-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.9);
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    color: #fff;
    font-size: 2rem;
    z-index: 9999;
  }

  /* Chat container */
  .chat-container {
    height: 80vh;
    display: flex;
    flex-direction: column;
    padding-bottom: 20vh;
  }

  /* Chat box (main area) */
  #chat-box {
    flex: 1;
    overflow-y: auto;
    border: 1px solid #ddd;
    border-radius: 10px;
    padding: 15px;
    background: #fff;
    position: relative; /* only for internal positioning */
  }

  .message {
    margin-bottom: 15px;
  }
  .bot {
    font-weight: bold;
    color: #0d6efd;
  }
  .user {
    font-weight: bold;
    color: #198754;
  }

  /* Camera fixed exactly at bottom-right inside chat-box */
  #camera {
    width: 200px;
    height: 150px;
    background: #000;
    border-radius: 10px;
    overflow: hidden;
    position: fixed;
    bottom: 20px;
    right: 20px;
    box-shadow: 0px 2px 10px rgba(0, 0, 0, 0.4);
    z-index: 1000;
  }

  #camera video {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }

  .main-screen {
    text-align: center;
  }

  #mic-container {
    position: absolute;
    bottom: 7%;
    left: 50%;
    transform: translateX(-50%);
  }

  #mic-btn {
    background: #007bff;
    border: none;
    border-radius: 50%;
    padding: 15px;
    cursor: pointer;
    color: white;
    font-size: 20px;
    box-shadow: 0 2px 6px rgba(0, 0, 0, 0.3);
  }

  #mic-btn:focus {
    outline: none;
  }

  #mic-icon {
    font-size: 22px;
  }

  .shape-left {
    left: 0;
    max-width: 0;
    overflow: hidden;
  }

  .message {
    display: flex;
    margin-bottom: 15px;
  }

  .message.question {
    justify-content: flex-start;
  }

  .message.answer {
    justify-content: flex-end;
  }

  .bubble {
    max-width: 70%;
    padding: 10px 15px;
    border-radius: 15px;
    word-wrap: break-word;
  }

  .bubble.question {
    background: #f1f1f1;
    color: #333;
    border-bottom-left-radius: 0;
  }

  .bubble.answer {
    background: #0d6efd;
    color: white;
    border-bottom-right-radius: 0;
  }
</style>

<!-- Countdown Overlay -->
<div id="countdown-overlay">
  <div id="countdown-message">
    Your interview will start in <span id="countdown">5</span> sec
  </div>
</div>

<div class="main-screen container mt-4 chat-container">
  <!-- Heading -->
  <h3 class="mb-3">Practice Interview</h3>

  <!-- Chat Area -->
  <div id="chat-box"></div>
  <!-- Camera attached inside -->
  <div id="camera">
    <video id="video" autoplay muted></video>
  </div>

  <!-- Mic button bottom center -->
  <div id="mic-container">
    <button id="mic-btn">
      <i id="mic-icon" class="fas fa-microphone"></i>
    </button>
  </div>
</div>

<!-- Summary Modal -->
<div id="summaryModal" style="
  position: fixed; top: 0; left: 0; width: 100%; height: 100%;
  background: rgba(0,0,0,0.5); display: none; justify-content: center; align-items: center;
  z-index: 9999;
">
  <div style="
    background: #fff;
    width: 60%;
    padding: 20px;
    border-radius: 8px;
    max-height: 80%;
    overflow-y: auto;
    position: relative;
  ">
    <h2>Interview Result Summary</h2>

    <div id="summaryContent"></div>

    <button onclick="closeSummaryModal()" style="
      margin-top: 20px;
      padding: 8px 16px;
      background: black;
      color:white;
      border:none;
      border-radius:4px;
      cursor:pointer;
    ">
      Close
    </button>
  </div>
</div>


<script>
  // === Camera & Mic Access ===
  navigator.mediaDevices
    .getUserMedia({ video: true, audio: true }) // ask for both
    .then((stream) => {
      // Attach camera stream to video element
      document.getElementById("video").srcObject = stream;

      // Save mic track but mute initially (control mic ON/OFF manually later)
      window.localStream = stream;
      window.audioTrack = stream.getAudioTracks()[0];
      if (window.audioTrack) {
        window.audioTrack.enabled = false; // keep mic OFF by default
        console.log("Mic access granted but OFF initially");
      }
    })
    .catch((err) => console.error("Camera/Mic access denied:", err));

  // === Countdown Overlay ===
  let countdown = 5;
  const countdownElement = document.getElementById("countdown");
  const overlay = document.getElementById("countdown-overlay");

  const timer = setInterval(() => {
    countdown--;
    countdownElement.textContent = countdown;
    if (countdown <= 0) {
      clearInterval(timer);
      overlay.style.display = "none"; // Hide overlay
      // TODO: Connect websocket here
      connectWebSocket();
    }
  }, 1000);
</script>

<script>
  function openSummaryModal(summaryHTML) {
    document.getElementById("summaryContent").innerHTML = summaryHTML;
    document.getElementById("summaryModal").style.display = "flex";
  }

  function closeSummaryModal() {
    console.log("Closing summary modal");
    document.getElementById("summaryModal").style.display = "none";
  }

  let socket = null;
  let micIcon = document.getElementById("mic-icon");

  function connectWebSocket() {
    // Replace this with your actual backend WebSocket endpoint
    const wsUrl = "ws://127.0.0.1:8000/ws/interview/";

    socket = new WebSocket(wsUrl);

    socket.onopen = function () {
      console.log("âœ… WebSocket connected");
      // Example: send initial message if needed
      // socket.send(JSON.stringify({ message: "Interview started" }));
    };

    socket.onmessage = function (event) {
      const data = JSON.parse(event.data);
      console.log("ðŸ“© Message from server:", data);
      if (data.type === "session_complete" && data.summary) {
        const s = data.summary;

        const html = `
          <div style="font-family: Arial, sans-serif; line-height: 1.5;">
            
            <h3>Candidate Details</h3>
            <p><strong>Name:</strong> ${s.candidate_details.name}</p>
            <p><strong>Interview Mode:</strong> ${s.candidate_details.interview_mode}</p>
            <p><strong>Difficulty:</strong> ${s.candidate_details.difficulty_level}</p>
            <p><strong>Date & Time:</strong> ${s.candidate_details.date_time}</p>

            <hr>

            <h3>Interview Summary</h3>
            <p><strong>Total Questions:</strong> ${s.interview_summary.total_questions}</p>

            ${
              s.interview_summary.summary_text?.strengths
                ? `<p><strong>Strengths:</strong> ${s.interview_summary.summary_text.strengths}</p>`
                : ""
            }
            ${
              s.interview_summary.summary_text?.weaknesses
                ? `<p><strong>Weaknesses:</strong> ${s.interview_summary.summary_text.weaknesses}</p>`
                : ""
            }
            ${
              s.interview_summary.summary_text?.engagement
                ? `<p><strong>Engagement:</strong> ${s.interview_summary.summary_text.engagement}</p>`
                : ""
            }

            <hr>

            <h3>Technical Questions</h3>
            ${
              s.tech_section.length > 0
                ? s.tech_section
                    .map(
                      (q, i) => `
                    <div style="margin-bottom: 12px;">
                      <p><b>Q${i + 1}:</b> ${q.question}</p>
                      <p><b>A${i + 1}:</b> ${q.answer}</p>
                      <p><i>${q.comment || ""}</i></p>
                      <p><b>Score:</b> ${q.score}/5</p>
                    </div>`
                    )
                    .join("")
                : "<p>No technical questions answered.</p>"
            }

            <hr>

            <h3>Overall Performance</h3>
            <p><strong>Average Score:</strong> ${s.overall.average_score}/5</p>
            <p><strong>Rating:</strong> ${s.overall.rating}</p>

            <hr>

            <h3>Recommendations</h3>
            ${
              s.recommendations.length > 0
                ? `<ul>${s.recommendations.map((r) => `<li>${r}</li>`).join("")}</ul>`
                : "<p>No specific recommendations.</p>"
            }

          </div>
        `;

        openSummaryModal(html);
      }



      // Example: append message to chat box
      const chatBox = document.getElementById("chat-box");
      if (chatBox) {
        // Show question (if exists)
        if (data.question) {
          const qDiv = document.createElement("div");
          qDiv.className = "message question";
          qDiv.innerHTML = `<div class="bubble question">${data.question}</div>`;
          chatBox.appendChild(qDiv);

          // ðŸ”Š Play audio of the question
          micIcon.className = "fas fa-microphone-slash";
          const utterance = new SpeechSynthesisUtterance(data.question);
          utterance.lang = "en-US";
          window.speechSynthesis.speak(utterance);
          utterance.onend = () => {
            startMic();
          };
        }

        // Show answer (if exists)
        if (data.answer) {
          const aDiv = document.createElement("div");
          aDiv.className = "message answer";
          aDiv.innerHTML = `<div class="bubble answer">${data.answer}</div>`;
          chatBox.appendChild(aDiv);
        }

        // Auto scroll
        chatBox.scrollTop = chatBox.scrollHeight;
      }
    };

    socket.onclose = function () {};

    socket.onerror = function (error) {};
  }

  let micStream;
  let mediaRecorder;
  let audioChunks = [];
  let audioContext, analyser, dataArray, source;
  let silenceTimer = null;

  async function startMic() {
    micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(micStream, { mimeType: "audio/webm" });

    // Collect chunks only while recording
    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    // When speech fully ends â†’ send blob
    mediaRecorder.onstop = () => {
      if (audioChunks.length > 0) {
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        audioChunks = []; // reset for next speech

        if (socket && socket.readyState === WebSocket.OPEN) {
          console.log("ðŸ“¤ Sending full speech to backend:", audioBlob);
          socket.send(audioBlob);
        }
      }

      stopMic(); // fully stop mic after sending
    };

    // ---- Setup analyser for speech detection ----
    audioContext = new AudioContext();
    source = audioContext.createMediaStreamSource(micStream);
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 2048;
    dataArray = new Uint8Array(analyser.fftSize);
    freqData = new Uint8Array(analyser.frequencyBinCount); // frequency-domain
    source.connect(analyser);

    detectSpeech(); // start detection loop

    document.getElementById("mic-icon").className =
      "fas fa-microphone text-green-500";
  }

  let noiseFloor = 0.01;   // gets auto-learned
  let smoothing = 0.95;    // noise floor smoothing factor

  function detectSpeech() {
    analyser.getByteTimeDomainData(dataArray);
    // --- Frequency check (human voice range ~85 Hz to 4000 Hz) ---
    analyser.getByteFrequencyData(freqData);

    const sampleRate = audioContext.sampleRate; // usually 44100 Hz
    const nyquist = sampleRate / 2; // max frequency
    const freqStep = nyquist / freqData.length;

    let humanEnergy = 0;
    let totalEnergy = 0;

    for (let i = 0; i < freqData.length; i++) {
      const freq = i * freqStep;
      const mag = freqData[i];
      totalEnergy += mag;

      if (freq >= 85 && freq <= 4000) {
        humanEnergy += mag;
      }
    }

    const humanRatio = humanEnergy / (totalEnergy + 1);

    // Calculate RMS volume
    let sumSquares = 0;
    for (let i = 0; i < dataArray.length; i++) {
      const val = (dataArray[i] - 128) / 128;
      sumSquares += val * val;
    }
    const rms = Math.sqrt(sumSquares / dataArray.length);

    // Adaptive noise floor update (only when no speech detected)
    noiseFloor = smoothing * noiseFloor + (1 - smoothing) * rms;

    // Dynamic speech threshold
    const threshold = noiseFloor * 3; // 3x louder than background noise

    const speaking = rms > threshold && humanRatio > 0.45;
    // const speaking = rms > 0.02 && humanRatio > 0.3;

    if (speaking) {
      console.log("ðŸŽ¤ Speaking...");
      if (mediaRecorder.state === "inactive") {
        console.log("â–¶ï¸ Started recording...");
        mediaRecorder.start();
      }

      // Reset silence timer (user resumed speaking)
      if (silenceTimer) {
        clearTimeout(silenceTimer);
        silenceTimer = null;
      }
    } else {
      // If recording â†’ consider stopping only after a long pause
      if (mediaRecorder.state === "recording" && !silenceTimer) {
        silenceTimer = setTimeout(() => {
          console.log("â¹ï¸ Long silence detected â†’ stopping mic");
          mediaRecorder.stop();
        }, 5000); // 5 sec pause considered end of speech
      }
    }

    requestAnimationFrame(detectSpeech);
  }

  // Stop mic completely
  function stopMic() {
    if (micStream) {
      micStream.getTracks().forEach((track) => track.stop());
      micStream = null;
    }
    if (audioContext) {
      audioContext.close();
      audioContext = null;
    }
    document.getElementById("mic-icon").className =
      "fas fa-microphone text-red-500";
  }

  // Stop Mic
  function stopMic() {
    if (mediaRecorder && mediaRecorder.state !== "inactive") {
      mediaRecorder.stop();
    }
    if (micStream) {
      micStream.getTracks().forEach((track) => track.stop());
    }
    document.getElementById("mic-icon").className =
      "fas fa-microphone-slash text-red-500";
    micEnabled = false;
  }
</script>

<script>
  document.getElementById("summaryModal").addEventListener("click", function(e) {
    if (e.target.id === "summaryModal") closeSummaryModal();
  });

</script>

{% endblock content %}
